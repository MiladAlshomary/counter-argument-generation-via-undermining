{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code for training an LTR with bert for ranking weak premises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../lib/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '6'\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace data_path with the folder that contains the Jo et al data\n",
    "data_path = '/workspace/ceph_data/argument-undermining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_df(df):\n",
    "    df = df.groupby('title').agg({\n",
    "        'title' : lambda x: list(x)[0],\n",
    "        'full_post': lambda x: list(x)[0],\n",
    "        'premise_counter_premise_pair': lambda x : [attack for comment in list(x) for attack in comment],\n",
    "    }).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_jo_to_json(df):\n",
    "    ranking_problems = []\n",
    "    for idx, row in df.iterrows():\n",
    "            documents = []\n",
    "            attacked_idx = row['qouted_sent_idx']\n",
    "            for sent_idx, sent in enumerate(row['post']):\n",
    "                documents.append({\"relevance\": attacked_idx[sent_idx], \n",
    "                 \"docText\": sent})\n",
    "            \n",
    "            ranking_problems.append({\n",
    "                \"queryText\": row['title'],\n",
    "                \"documents\": documents\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"rankingProblems\": ranking_problems\n",
    "    }\n",
    "\n",
    "def trim_documents(problem, max_sents=15):\n",
    "    '''\n",
    "    Take top 15 sentences, making sure that the relevant sentences are kept and then shuffle.\n",
    "    '''\n",
    "    sorted_by_rel = sorted(problem['documents'], key=lambda x: -x['relevance'])\n",
    "    sorted_by_rel = sorted_by_rel[0:max_sents]\n",
    "    np.random.shuffle(sorted_by_rel)\n",
    "    problem['documents'] =  sorted_by_rel\n",
    "    \n",
    "    return problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Jo et. al. Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "jo_df = pd.read_pickle(data_path + '/jo_data/vul_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jo_training_json = convert_jo_to_json (jo_df[jo_df.split=='train'])\n",
    "jo_valid_json    = convert_jo_to_json(jo_df[jo_df.split=='val'])\n",
    "jo_testing_json  = convert_jo_to_json(jo_df[jo_df.split=='test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25839\n",
      "8763\n",
      "8558\n"
     ]
    }
   ],
   "source": [
    "print(len(jo_training_json['rankingProblems']))\n",
    "print(len(jo_valid_json['rankingProblems']))\n",
    "print(len(jo_testing_json['rankingProblems']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevants_dist = [sum([doc['relevance'] for doc in p['documents']]) for p in jo_training_json['rankingProblems']]\n",
    "plt.hist(relevants_dist, bins=[0,1,2,3,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_sents_dist = [len(p['documents']) for p in jo_training_json['rankingProblems']]\n",
    "plt.hist(num_sents_dist, bins=[3,6,9,15,20, 25, 30, 35])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(jo_training_json, open(data_path+'/data/vul_detection/jo_training.json', 'w'))\n",
    "json.dump(jo_valid_json, open(data_path+'/data/vul_detection/jo_valid.json', 'w'))\n",
    "json.dump(jo_testing_json, open(data_path+'/data/vul_detection/jo_testing.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LTR-BERT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 12:26:55.136957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Utility to convert between JSON and ELWC for TFR-Bert\n",
      "\n",
      "Model Parameters: \n",
      "Vocabulary filename: /workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2/vocab.txt\n",
      "sequence_length: 128\n",
      "do_lower_case: True\n",
      "\n",
      "\n",
      "Input file:  /workspace/ceph_data/argument-undermining/data/vul_detection/training.json\n",
      "Output file: /workspace/ceph_data/argument-undermining/data/vul_detection/training.elwc.tfrecord\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "RANKING_CODE=\"/workspace/computationally-undermining-arguments/thirdparty\"\n",
    "VOCAN_PATH  = \"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2/vocab.txt\"\n",
    "DATA_PATH   =\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "\n",
    "!python ${RANKING_CODE_PATH}/ranking/tensorflow_ranking/extension/examples/tfrbert_convert_json_to_elwc.py \\\n",
    "    --vocab_file= ${VOCAB_PATH} \\\n",
    "    --sequence_length=128 \\\n",
    "    --input_file=${DATA_PATH}/vul_detection/jo_train.json \\\n",
    "    --output_file=${DATA_PATH}/vul_detection/jo_train.elwc.tfrecord \\\n",
    "    --do_lower_case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 12:29:03.432798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Utility to convert between JSON and ELWC for TFR-Bert\n",
      "\n",
      "Model Parameters: \n",
      "Vocabulary filename: /workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2//vocab.txt\n",
      "sequence_length: 128\n",
      "do_lower_case: True\n",
      "\n",
      "\n",
      "Input file:  /workspace/ceph_data/argument-undermining/data/vul_detection/valid.json\n",
      "Output file: /workspace/ceph_data/argument-undermining/data/vul_detection/valid.elwc.tfrecord\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "RANKING_CODE=\"/workspace/computationally-undermining-arguments/thirdparty\"\n",
    "VOCAN_PATH  = \"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2/vocab.txt\"\n",
    "DATA_PATH   =\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "\n",
    "!python ${RANKING_CODE_PATH}/ranking/tensorflow_ranking/extension/examples/tfrbert_convert_json_to_elwc.py \\\n",
    "    --vocab_file= ${VOCAB_PATH} \\\n",
    "    --sequence_length=128 \\\n",
    "    --input_file=${DATA_PATH}/vul_detection/jo_valid.json \\\n",
    "    --output_file=${DATA_PATH}/vul_detection/jo_valid.elwc.tfrecord \\\n",
    "    --do_lower_case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bazel build -c opt bazel build -c opt tensorflow_ranking/extension/examples:tfrbert_example_py_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training LTR-BERT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are commands to train an LTR-BERT model on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_DIR=\"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2\" #big-bert\n",
    "DATA_DIR=\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "BAZIL_BIN=\"/workspace/computationally-undermining-arguments/thirdparty/ranking/bazel-bin/\" #path to the built library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"/workspace/ceph_data/argument-undermining/models/jo_vul_detection_listwise/\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=7 ${BAZIL_BIN}/tensorflow_ranking/extension/examples/tfrbert_example_py_binary \\\n",
    "   --train_input_pattern=${DATA_DIR}/jo_training.elwc.tfrecord \\\n",
    "   --eval_input_pattern=${DATA_DIR}/jo_valid.elwc.tfrecord \\\n",
    "   --bert_config_file=${BERT_DIR}/bert_config.json \\\n",
    "   --bert_init_ckpt=${BERT_DIR}/bert_model.ckpt \\\n",
    "   --bert_max_seq_length=128 \\\n",
    "   --model_dir=\"${OUTPUT_DIR}\" \\\n",
    "   --loss=softmax_loss \\\n",
    "   --train_batch_size=1 \\\n",
    "   --convert_labels_to_binary \\\n",
    "   --eval_batch_size=1 \\\n",
    "   --listwise_inference True \\\n",
    "   --list_size=25 \\\n",
    "   --learning_rate=1e-6 \\\n",
    "   --num_train_steps=30000 \\\n",
    "   --num_eval_steps=200 \\\n",
    "   --checkpoint_secs=200 \\\n",
    "   --bert_num_warmup_steps 1000 \\\n",
    "   --num_checkpoints=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"/workspace/ceph_data/argument-undermining/models/jo_vul_detection_pairwise/\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=6 ${BAZIL_BIN}/tensorflow_ranking/extension/examples/tfrbert_example_py_binary \\\n",
    "   --train_input_pattern=${DATA_DIR}/jo_training.elwc.tfrecord \\\n",
    "   --eval_input_pattern=${DATA_DIR}/jo_valid.elwc.tfrecord \\\n",
    "   --bert_config_file=${BERT_DIR}/bert_config.json \\\n",
    "   --bert_init_ckpt=${BERT_DIR}/bert_model.ckpt \\\n",
    "   --bert_max_seq_length=128 \\\n",
    "   --model_dir=\"${OUTPUT_DIR}\" \\\n",
    "   --loss=pairwise_logistic_loss \\\n",
    "   --train_batch_size=1 \\\n",
    "   --convert_labels_to_binary \\\n",
    "   --eval_batch_size=1 \\\n",
    "   --listwise_inference True \\\n",
    "   --list_size=25 \\\n",
    "   --learning_rate=1e-6 \\\n",
    "   --num_train_steps=30000 \\\n",
    "   --num_eval_steps=200 \\\n",
    "   --checkpoint_secs=200 \\\n",
    "   --bert_num_warmup_steps 1000 \\\n",
    "   --num_checkpoints=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"/workspace/ceph_data/argument-undermining/models/jo_vul_detection_pointwise/\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=5 ${BAZIL_BIN}/tensorflow_ranking/extension/examples/tfrbert_example_py_binary \\\n",
    "   --train_input_pattern=${DATA_DIR}/jo_training.elwc.tfrecord \\\n",
    "   --eval_input_pattern=${DATA_DIR}/jo_valid.elwc.tfrecord \\\n",
    "   --bert_config_file=${BERT_DIR}/bert_config.json \\\n",
    "   --bert_init_ckpt=${BERT_DIR}/bert_model.ckpt \\\n",
    "   --bert_max_seq_length=128 \\\n",
    "   --model_dir=\"${OUTPUT_DIR}\" \\\n",
    "   --loss=sigmoid_cross_entropy_loss \\\n",
    "   --train_batch_size=1 \\\n",
    "   --convert_labels_to_binary \\\n",
    "   --eval_batch_size=1 \\\n",
    "   --listwise_inference True \\\n",
    "   --list_size=25 \\\n",
    "   --learning_rate=1e-6 \\\n",
    "   --num_train_steps=30000 \\\n",
    "   --num_eval_steps=200 \\\n",
    "   --checkpoint_secs=200 \\\n",
    "   --bert_num_warmup_steps 1000 \\\n",
    "   --num_checkpoints=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands to setup the tensorflow predictions server for each of the model, and perform prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL_DIR=/workspace/ceph_data/argument-undermining/models/jo_vul_detection_listwise/export/best_model_by_loss/\n",
    "CUDA_VISIBLE_DEVICES=2 tensorflow_model_server \\\n",
    "  --port=8503 \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=tfrbert \\\n",
    "  --model_base_path=\"${MODEL_DIR}\"\n",
    "\n",
    "#!/bin/bash\n",
    "BERT_DIR=\"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2\"\n",
    "DATA_DIR=\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "python tensorflow_ranking/extension/examples/tfrbert_client_predict_from_json.py \\\n",
    "    --vocab_file=${BERT_DIR}/vocab.txt \\\n",
    "    --server_port 8503 \\\n",
    "    --sequence_length=128 \\\n",
    "    --input_file=${DATA_DIR}/jo_testing.json \\\n",
    "    --output_file=${DATA_DIR}/listwise-pred-jo-test-tmp.json \\\n",
    "    --do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL_DIR=/workspace/ceph_data/argument-undermining/models/jo_vul_detection_pointwise/export/best_model_by_loss/\n",
    "CUDA_VISIBLE_DEVICES=2 tensorflow_model_server \\\n",
    "  --port=8503 \\\n",
    "  --rest_api_port=8506 \\\n",
    "  --model_name=tfrbert \\\n",
    "  --model_base_path=\"${MODEL_DIR}\"\n",
    "\n",
    "#!/bin/bash\n",
    "BERT_DIR=\"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2\"\n",
    "DATA_DIR=\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "python tensorflow_ranking/extension/examples/tfrbert_client_predict_from_json.py \\\n",
    "    --vocab_file=${BERT_DIR}/vocab.txt \\\n",
    "    --server_port 8503 \\\n",
    "    --sequence_length=128 \\\n",
    "    --input_file=${DATA_DIR}/jo_testing.json \\\n",
    "    --output_file=${DATA_DIR}/pointwise-pred-jo-test.json \\\n",
    "    --do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL_DIR=/workspace/ceph_data/argument-undermining/models/jo_vul_detection_pairwise/export/best_model_by_loss/\n",
    "CUDA_VISIBLE_DEVICES=2 tensorflow_model_server \\\n",
    "  --port=8507 \\\n",
    "  --rest_api_port=8508 \\\n",
    "  --model_name=tfrbert \\\n",
    "  --model_base_path=\"${MODEL_DIR}\"\n",
    "\n",
    "#!/bin/bash\n",
    "BERT_DIR=\"/workspace/ceph_data/argument-undermining/models/thirdparty/uncased_L-12_H-768_A-12_TF2\"\n",
    "DATA_DIR=\"/workspace/ceph_data/argument-undermining/data/vul_detection\"\n",
    "python tensorflow_ranking/extension/examples/tfrbert_client_predict_from_json.py \\\n",
    "    --vocab_file=${BERT_DIR}/vocab.txt \\\n",
    "    --server_port 8507 \\\n",
    "    --sequence_length=128 \\\n",
    "    --input_file=${DATA_DIR}/jo_testing.json \\\n",
    "    --output_file=${DATA_DIR}/pairwise-pred-jo-test.json \\\n",
    "    --do_lower_case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
